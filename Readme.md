# Watson AIOps – Automated Problem Resolution

## Background
The AIOps is designed to monitor IT and other Systems, detect and correlate potential problems, and minimize system downtime.

![](doc-images\image.png)


## Problem Statement

For critical outages or any other problems, an automated system must ingest and analyze the various logs, kpis and alerts generated by the system and execute any pre-defined mitigation steps automatically. This will ensure reduced mean time to diagnose (MTTD) and mean time to resolve (MTTR)

![](doc-images\image3.png)

Alerts generated by various resources in the system

Below is the requirement for data ingestion and allocation of generated alerts to various resources like servers and hypervisors.

![](doc-images\image2.png)

Nodes like hypervisors and servers are organized in the graph topology

The cloud resources must be organized and cached as graph data structures. The Alerts generated by the various resources must be consumed and identify the Node/Resource associated with that Alert.

Inputs:

- **Node data** is available to consume from Kafka by Topic ‘node-topological-data’
    - Contains resource object having hostname and IP address.
- **Edge data** is available to consume from Kafka by Topic 'edge-topological-data’
    - Contains the ‘From Node’ id, ‘To Node’ id, and the edge type (or relation)
- **Alert data** is available to consume from Kafka by Topic ‘alert’
    - Contains resource object having hostname and IP address.

Requirements:

1. Consume Node, Edge, and Alert data from Kafka Topics
1. Organize the formation of a graph structure using these consumed Node and Edge data
    1. So that this structure can be queried later to extract topological information of various resources.
1. While consuming the Alerts, identify the Nodes having similar hostname or IP address.


## Graph formation Proposal 1
![](doc-images\image1.png)

The proposed system has a microservices architecture and is responsible for:

- Consume Node, Edge, and Alert data
- Parse these Json data to build Java class objects
- Construct a Graph structure within this microservice process itself, so that the graph will be formed within the Service memory.
- While consuming the Alerts, identify the Nodes having similar hostname or IP address.

Advantages

- Simple to implement

Disadvantages

- As the graph is formed within the service memory, the graph information could not be persisted reliably. The cached information will be removed when the cluster dynamically releases and re-allocates microservice instances based on the cluster policies.
- Syncing the graph information across different microservices is a resource-intensive task.
- As Kafka stores and manages the data under various topics in several partitions, the process organized in the microservices must be capable of handling duplications and missing of data while aggregating.

## Graph Formation Proposal 2 (Implemented)

The proposed system has a microservices architecture and is responsible for:

- Consume Node, Edge, and Alert data
- Parse these Json data to build Java class objects
- Construct a Graph structure within the Kafka instance itself, so that it will be available for all services in the cluster
- While consuming the Alerts, identify the Nodes having similar hostname or IP address.
- **Use Kafka Stream processing for data ingestion and transformations.**


![](doc-images\image4.png)

Here the Graph is formed within the Kafka itself under the Topic ‘node-adjacent-list’, and there is nothing stored in the microservices so a failure will not cause data loss.

From the Alert’s Hostname and IP address, the associated Node is identified and mapped and listed in the Kafka under Topic ‘alert-node-map’.

As these results are available under topics, any microservice or other cloud services can consume them by using Kafka consumers or streams.

![](doc-images\image5.png)

Kafka Streams Processor Topology – High level design

Advantages

- As the Graph is formed within the Kafka itself the persistence is reliable. The Graph data will not be lost even if the microservices are down.
- Kafka has inbuilt Disaster recovery to handle the data processing when the application service is down or crashed while processing.
- The results after data processing (The Graph structure and data) are available to all services in the cluster and can be consumed from Kafka using Topics.
- Kafka Streams can handle the partitioned data under topics efficiently so no specific implementation is required in the microservices.

Disadvantages

- Require complex KStream and KTable processing steps.
- Gradual memory growth in Kafka

## Strategy For Handling Failure of High Availability (HA) and Disaster Recovery (DR)
The proposed system consists of a self-organized Kafka Cluster and a microservices cluster.
### Microservices cluster
- Here the High availability of the services depends on the configuration and the cluster platform.
- Platforms like Kubernetes have inbuilt facilities to ensure HA.
- Microservices are deployed in Pods which can be configured to have multiple replicas.
- The Components like kubelet and kubeproxy will ensure that the configured number of pods are always available.
- These Pods are arranged in Nodes (Virtual or physical machines), and these Nodes are also scalable.
- So, the cluster itself has a self-healing capacity.
- Also, the Microservices in this problem context are not storing any results or intermediate states within it. So, a Failure will not result in data loss.
### Kafka Cluster
- Kafka has an inbuilt feature to create and handle multiple copies of the data stored.
- Data partitioning distributes the load across multiple Kafka brokers. This ensures that even if one broker fails, the others can continue processing their assigned partitions.
- Use automated scaling mechanisms to adapt to changing workloads. This could involve automatically adjusting the number of Kafka Brokers, Kafka Stream application instances, or other resources based on demand.

## Handling Memory growth within the system

- The microservice instances are not storing any data within it, instead it processes streams of data from Kafka.
- The resources that will consume memory are the cached GlobalKTables. These tables contain the complete data from Kafka and are in sync with the GlobalKTables in other microservices instances.
- As a resolution to this memory growth the microservice memory requirements can be increased by configuring the Pod and Node settings in the cluster.

## Improvements/Future enhancements
### Memory and Caching
The major issue in the proposed system is the gradual increase in memory consumption. This is due to the growing Graph topology within the Kafka instance.

As a resolution to this problem, the growing graph structure can be cached to a reliable Graph Database deployed outside of the Kafka Cluster. Apache Tinker pop – Gremlin DB and Neo4j DB are some of the examples of such reliable Graph DB technologies.

The Graph structure generated within the microservice can be cached in the GraphDB as shown below:

![](doc-images\image6.png)

### Handle Graph topology changes
#### *Removal of an Edge*
Edge removal must remove entries from the Node Adjacent list and must update to Topic.
#### *Removal of a Node*
Node removal must update Node adjacent list, and remove any associated Edges and Alerts. Update these changes to corresponding Topics.
#### *Handle new Edge having its Nodes missing.*
For a new Edge, if its ‘From’ and/or ‘To’ Nodes are missing. Then it should not be processed and cached.
#### *Cleanup and update the data under the temporary topics*
The topics like: ‘nodeid-ip-map’ and ‘nodeid-host-map’ must be updated properly when new Nodes are added and existing ones are updated. A garbage collection and cleanup procedure must be implemented along with the facilities available in Kafka to efficiently utilize memory.
#### *Remove Alerts*
Removing the alerts must remove the alert-node map data. Update this information to associated Topic.





